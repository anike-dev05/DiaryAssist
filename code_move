

# Create a DataFrame from percentiles
percentiles_df = spark.createDataFrame([(percentiles,)], ["percentiles"])

# Explode the percentiles into individual rows and add the percentile label
percentiles_df = percentiles_df.select(F.posexplode("percentiles").alias("decile", "gb_score"))

# Assign deciles and calculate min/max scores
df = df.withColumn(
    "decile",
    when(col("gb_score") <= percentiles[1], 0)
    .when(col("gb_score") <= percentiles[2], 1)
    .when(col("gb_score") <= percentiles[3], 2)
    .when(col("gb_score") <= percentiles[4], 3)
    .when(col("gb_score") <= percentiles[5], 4)
    .when(col("gb_score") <= percentiles[6], 5)
    .when(col("gb_score") <= percentiles[7], 6)
    .when(col("gb_score") <= percentiles[8], 7)
    .when(col("gb_score") <= percentiles[9], 8)
    .otherwise(9)
)

# Create a DataFrame for the min/max scores
min_max_scores = [(i, percentiles[i], percentiles[i + 1]) for i in range(10)]

# Convert to DataFrame
min_max_df = spark.createDataFrame(min_max_scores, ["decile", "m1", "m2"])

# Join with the original DataFrame to add min/max scores
df = df.join(min_max_df, on="decile", how="left")

# Select and rename columns for the final output
final_df = df.select("decile", "m1", "m2")

# Show the result
final_df.show(truncate=False)