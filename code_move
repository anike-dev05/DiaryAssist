
from pyspark.sql import functions as F

# Assuming df is your DataFrame and the column is '_n_time_at_curr_addr'

df = df.withColumn(
    "Months_in_Current_Address",
    (F.floor(F.col("_n_time_at_curr_addr") / 100) * 12) + (F.col("_n_time_at_curr_addr") % 100)
)

# Drop the old column if necessary
df = df.drop("_n_time_at_curr_addr")

# Show the updated DataFrame
df.show()