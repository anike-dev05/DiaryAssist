To convert the SAS code snippet into PySpark code, you can use the `when` and `otherwise` functions to assign values to the `Bureau_Status` column based on the condition `br_age_oldst_acc > 2`. Hereâ€™s how you can do it:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when

# Assuming you have a SparkSession named 'spark'
spark = SparkSession.builder \
    .appName("Bureau Status Processing") \
    .getOrCreate()

# Assuming you have a DataFrame named 'df' containing the relevant columns
# br_age_oldst_acc

df = spark.read.csv("path_to_your_data.csv", header=True)  # Adjust as per your data source

# Applying the condition
df = df.withColumn("Bureau_Status",
    when(col("br_age_oldst_acc") > 2, "Vintage Bureau")
    .otherwise("New_to_Bureau")
)

# Show the resulting DataFrame
df.show()
```

### Explanation:

1. **Reading Data**: Assumes you read your data into a DataFrame `df`.

2. **Column Operations**:
   - `.withColumn("Bureau_Status", ...)` adds a new column "Bureau_Status" based on the conditions.

3. **Condition**:
   - `when(col("br_age_oldst_acc") > 2, "Vintage Bureau")` checks if the value in the `br_age_oldst_acc` column is greater than 2. If true, assigns "Vintage Bureau" to `Bureau_Status`.
   - `.otherwise("New_to_Bureau")` assigns "New_to_Bureau" to `Bureau_Status` when the condition is not met (i.e., when `br_age_oldst_acc` is not greater than 2).

4. **Result**:
   - The `Bureau_Status` column in the resulting DataFrame will reflect "Vintage Bureau" for rows where `br_age_oldst_acc` > 2, and "New_to_Bureau" otherwise.

5. **Output**:
   - Finally, `.show()` displays the resulting DataFrame with the "Bureau_Status" column populated accordingly.

Make sure to replace `"path_to_your_data.csv"` with the actual path to your data file or adjust the DataFrame creation part (`df = ...`) to match your data loading process. Adjust column names (`col("