Certainly! We can use the elbow method to find the optimal number of clusters. Here's how you can do it in Python:

```python
import matplotlib.pyplot as plt
import numpy as np

# Assuming your data is in a DataFrame named 'df'
# Replace 'df' with the name of your DataFrame if different

# Selecting the features for clustering (excluding the account number)
X = df.iloc[:, 1:]

# Initializing an empty list to store the sum of squared distances
sse = []

# Trying different values of k from 1 to 10
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    sse.append(kmeans.inertia_)

# Plotting the elbow curve
plt.figure(figsize=(8, 6))
plt.plot(range(1, 11), sse, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Sum of Squared Distances')
plt.title('Elbow Method')
plt.xticks(np.arange(1, 11, 1))
plt.grid(True)
plt.show()
```

In this code:
- We iterate over different values of `k` (number of clusters) from 1 to 10.
- For each value of `k`, we fit a KMeans model and calculate the sum of squared distances of samples to their closest cluster center (`inertia_`).
- We store these values in the `sse` list.
- Finally, we plot the elbow curve to visualize the relationship between the number of clusters and the sum of squared distances. The optimal number of clusters can be chosen based on the point where the curve starts to bend or level off, resembling an "elbow".