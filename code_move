from pyspark.sql import SparkSession
from pyspark.sql.functions import col, expr, when

# Assuming you have a SparkSession named 'spark'
spark = SparkSession.builder \
    .appName("SAS to PySpark conversion") \
    .getOrCreate()

# Assuming 'p_dbt_brdn_ratio' is a column in your DataFrame
# Load your DataFrame here, replace with your actual DataFrame loading code
# df = spark.read.csv("path_to_your_file.csv", header=True)

# Applying the conversion logic
df = df.withColumn(
    'p_dbt_brdn_ratio',
    when(col('p_dbt_brdn_ratio').isNull() | (col('p_dbt_brdn_ratio') == ''),
         expr("0").cast('double'))
    .otherwise(col('p_dbt_brdn_ratio').cast('double'))
)

# Display the transformed DataFrame
df.show()